{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Juan Pablo Fonseca Correa  138263\n",
    "### Ejercicio de validación cruzada para determinar la mejor lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importar librerías y leer la base de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sys import maxint\n",
    "from math import pow\n",
    "from math import fabs\n",
    "from __future__ import division\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from random import uniform\n",
    "df = pd.read_csv('regLinPoli2.csv') # leo la bd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\juanpa~1\\desktop\\env1\\python~1\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# separar en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[df.columns[0:-1]],df[df.columns[-1]], train_size=0.75)\n",
    "p = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vap(x, coeff):\n",
    "    vap = 0\n",
    "    for i in range(0,p+1):\n",
    "        vap += coeff[i]*x[i]\n",
    "    return vap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# error siempre calculado sobre el conjunto de APRENDIZAJE\n",
    "def errorK(coeff,j):\n",
    "    y = coeff[0]\n",
    "    for i in range(0,p):\n",
    "        y += coeff[i+1]*cjAprend_sc[j][:,i]\n",
    "    errores = [pow(y[i]-yAprend[j].iloc[i],2) for i in range(0,len(yAprend[j].values))]\n",
    "    error = sum(errores)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 7 # k-fold cross validation; la k se puede modificar en esta línea\n",
    "X_trainK = []\n",
    "Y_trainK = []\n",
    "noTuplas = X_train.shape[0]\n",
    "for i in range(0,k):\n",
    "    X_trainK.append(X_train.iloc[int(i*noTuplas/k):int((i+1)*noTuplas/k)-1,:])\n",
    "    Y_trainK.append(Y_train.iloc[int(i*noTuplas/k):int((i+1)*noTuplas/k)-1])\n",
    "cjAprend = [] # conjuntos de aprendizaje\n",
    "cjValid = [] # conjuntos de validación\n",
    "cjAprend_sc = [] # conjuntos de aprendizaje escalados\n",
    "cjValid_sc = [] # conjuntos de validación escalados\n",
    "yAprend = [] # y asociadas con cjAprend\n",
    "yValid = [] # y asociadas con cjValid\n",
    "tempX = [] # guardas los dataframes previo a mezclarlos/concatenarlos\n",
    "tempY = [] # guardas los series previo a mezclarlos\n",
    "for i in range(0,k):\n",
    "    for j in range(0,k):\n",
    "        if j == i:\n",
    "            cjValid.append(X_trainK[j])\n",
    "            yValid.append(Y_trainK[j])\n",
    "        else:\n",
    "            tempX.append(X_trainK[j])\n",
    "            tempY.append(Y_trainK[j])\n",
    "    cjAprend.append(pd.concat(tempX))\n",
    "    yAprend.append(pd.concat(tempY))\n",
    "    tempX = []\n",
    "    tempY = []\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(cjAprend[i])\n",
    "    cjAprend_sc.append(scaler.transform(cjAprend[i]))\n",
    "    cjValid_sc.append(scaler.transform(cjValid[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para lambda = 0.0, el error es: 1.37916278891e+44\n",
      "Para lambda = 0.001, el error es: 1.4204113683e+44\n",
      "Para lambda = 0.002, el error es: 1.50862489081e+44\n",
      "Para lambda = 0.003, el error es: 1.61066382079e+44\n",
      "Para lambda = 0.004, el error es: 1.71209072729e+44\n",
      "Para lambda = 0.005, el error es: 1.80701733662e+44\n",
      "Para lambda = 0.006, el error es: 1.89347104447e+44\n",
      "Para lambda = 0.007, el error es: 1.97124051374e+44\n",
      "Para lambda = 0.008, el error es: 2.04086276444e+44\n",
      "Para lambda = 0.009, el error es: 2.10314687027e+44\n",
      "Para lambda = 0.01, el error es: 2.15895386658e+44\n",
      "Para lambda = 0.011, el error es: 2.20910005817e+44\n",
      "Para lambda = 0.012, el error es: 2.25431968962e+44\n",
      "Para lambda = 0.013, el error es: 2.29525569445e+44\n",
      "Para lambda = 0.014, el error es: 2.33246313599e+44\n",
      "Para lambda = 0.015, el error es: 2.3664177878e+44\n",
      "Para lambda = 0.016, el error es: 2.39752620659e+44\n",
      "Para lambda = 0.017, el error es: 2.42613560783e+44\n",
      "Para lambda = 0.018, el error es: 2.45254283171e+44\n",
      "Para lambda = 0.019, el error es: 2.47700216848e+44\n",
      "Para lambda = 0.02, el error es: 2.49973204002e+44\n",
      "Para lambda = 0.021, el error es: 2.52092063399e+44\n",
      "Para lambda = 0.022, el error es: 2.540730622e+44\n",
      "Para lambda = 0.023, el error es: 2.55930309707e+44\n",
      "Para lambda = 0.024, el error es: 2.57676085586e+44\n",
      "Para lambda = 0.025, el error es: 2.59321113561e+44\n",
      "Para lambda = 0.026, el error es: 2.60874789974e+44\n",
      "Para lambda = 0.027, el error es: 2.62345375054e+44\n",
      "Para lambda = 0.028, el error es: 2.63740153401e+44\n",
      "Para lambda = 0.029, el error es: 2.65065569043e+44\n",
      "Para lambda = 0.03, el error es: 2.66327339441e+44\n",
      "Para lambda = 0.031, el error es: 2.67530552051e+44\n",
      "Para lambda = 0.032, el error es: 2.6867974638e+44\n",
      "Para lambda = 0.033, el error es: 2.69778983932e+44\n",
      "Para lambda = 0.034, el error es: 2.70831908047e+44\n",
      "Para lambda = 0.035, el error es: 2.71841795248e+44\n",
      "Para lambda = 0.036, el error es: 2.72811599427e+44\n",
      "Para lambda = 0.037, el error es: 2.73743990005e+44\n",
      "Para lambda = 0.038, el error es: 2.74641384967e+44\n",
      "Para lambda = 0.039, el error es: 2.7550597954e+44\n",
      "Para lambda = 0.04, el error es: 2.76339771168e+44\n",
      "Para lambda = 0.041, el error es: 2.77144581304e+44\n",
      "Para lambda = 0.042, el error es: 2.77922074473e+44\n",
      "Para lambda = 0.043, el error es: 2.78673774994e+44\n",
      "Para lambda = 0.044, el error es: 2.79401081674e+44\n",
      "Para lambda = 0.045, el error es: 2.80105280749e+44\n",
      "Para lambda = 0.046, el error es: 2.80787557302e+44\n",
      "Para lambda = 0.047, el error es: 2.81449005364e+44\n",
      "Para lambda = 0.048, el error es: 2.82090636857e+44\n",
      "Para lambda = 0.049, el error es: 2.82713389528e+44\n",
      "Para lambda = 0.05, el error es: 2.8331813401e+44\n",
      "Para lambda = 0.051, el error es: 2.83905680098e+44\n",
      "Para lambda = 0.052, el error es: 2.84476782356e+44\n",
      "Para lambda = 0.053, el error es: 2.85032145115e+44\n",
      "Para lambda = 0.054, el error es: 2.85572426948e+44\n",
      "Para lambda = 0.055, el error es: 2.86098244681e+44\n",
      "Para lambda = 0.056, el error es: 2.86610176987e+44\n",
      "Para lambda = 0.057, el error es: 2.87108767612e+44\n",
      "Para lambda = 0.058, el error es: 2.87594528284e+44\n",
      "Para lambda = 0.059, el error es: 2.88067941323e+44\n",
      "Para lambda = 0.06, el error es: 2.88529462007e+44\n",
      "Para lambda = 0.061, el error es: 2.88979520693e+44\n",
      "Para lambda = 0.062, el error es: 2.89418524752e+44\n",
      "Para lambda = 0.063, el error es: 2.89846860302e+44\n",
      "Para lambda = 0.064, el error es: 2.90264893797e+44\n",
      "Para lambda = 0.065, el error es: 2.90672973456e+44\n",
      "Para lambda = 0.066, el error es: 2.91071430565e+44\n",
      "Para lambda = 0.067, el error es: 2.91460580665e+44\n",
      "Para lambda = 0.068, el error es: 2.91840724634e+44\n",
      "Para lambda = 0.069, el error es: 2.92212149664e+44\n",
      "Para lambda = 0.07, el error es: 2.92575130168e+44\n",
      "Para lambda = 0.071, el error es: 2.92929928602e+44\n",
      "Para lambda = 0.072, el error es: 2.93276796214e+44\n",
      "Para lambda = 0.073, el error es: 2.93615973738e+44\n",
      "Para lambda = 0.074, el error es: 2.93947692028e+44\n",
      "Para lambda = 0.075, el error es: 2.94272172639e+44\n",
      "Para lambda = 0.076, el error es: 2.94589628365e+44\n",
      "Para lambda = 0.077, el error es: 2.94900263735e+44\n",
      "Para lambda = 0.078, el error es: 2.95204275465e+44\n",
      "Para lambda = 0.079, el error es: 2.95501852884e+44\n",
      "Para lambda = 0.08, el error es: 2.95793178323e+44\n",
      "Para lambda = 0.081, el error es: 2.96078427477e+44\n",
      "Para lambda = 0.082, el error es: 2.9635776974e+44\n",
      "Para lambda = 0.083, el error es: 2.96631368518e+44\n",
      "Para lambda = 0.084, el error es: 2.96899381519e+44\n",
      "Para lambda = 0.085, el error es: 2.97161961024e+44\n",
      "Para lambda = 0.086, el error es: 2.97419254138e+44\n",
      "Para lambda = 0.087, el error es: 2.97671403028e+44\n",
      "Para lambda = 0.088, el error es: 2.97918545144e+44\n",
      "Para lambda = 0.089, el error es: 2.98160813421e+44\n",
      "Para lambda = 0.09, el error es: 2.98398336481e+44\n",
      "Para lambda = 0.091, el error es: 2.98631238808e+44\n",
      "Para lambda = 0.092, el error es: 2.98859640922e+44\n",
      "Para lambda = 0.093, el error es: 2.99083659545e+44\n",
      "Para lambda = 0.094, el error es: 2.99303407743e+44\n",
      "Para lambda = 0.095, el error es: 2.99518995081e+44\n",
      "Para lambda = 0.096, el error es: 2.99730527751e+44\n",
      "Para lambda = 0.097, el error es: 2.99938108705e+44\n",
      "Para lambda = 0.098, el error es: 3.00141837773e+44\n",
      "Para lambda = 0.099, el error es: 3.00341811784e+44\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.arange(0,0.1,0.001) # lambdas que se van a probar\n",
    "errores = []\n",
    "for i in range(len(lambdas)):\n",
    "    err = []\n",
    "    for j in range(0,k):\n",
    "        w = [uniform(-5,5) for q in range(0,p+1)]\n",
    "        eta = 0.005 # fija\n",
    "        for a in range (0,len(cjAprend_sc[j])):\n",
    "            xa0 = [1]\n",
    "            xademas=[cjAprend_sc[j][a][b] for b in range(0,p)]\n",
    "            xa = xa0 + xademas\n",
    "            ya = yAprend[j].iloc[a]\n",
    "            error_actual = ya - Vap(xa,w)\n",
    "            # actualizas UNA vez para el dato i\n",
    "            for b in range(len(w)):\n",
    "                w[b] = w[b] + eta * error_actual * xa[b] - lambdas[i] * w[b]\n",
    "        # error\n",
    "        err.append(errorK(w,j))\n",
    "    print \"Para lambda = {0}, el error es: {1}\".format(lambdas[i],sum(err))\n",
    "    errores.append(sum(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mejor lambda es 0.0\n"
     ]
    }
   ],
   "source": [
    "indiceLambda = errores.index(min(errores))\n",
    "lam = lambdas[indiceLambda]\n",
    "print \"La mejor lambda es {0}\".format(lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Observamos que la mejor lambda en este caso es 0. Como en el primer ejercicio de regularización, los errores son menores con esta lambda que con cualquier otra. Sin embargo, existen bases de datos en las que la mejor lambda sea mayor a cero.\n",
    "#### Otro punto a considerar es que la eta = 0.005 y estaba fija. Quizá con otra eta, la lambda óptima sería distinta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
